{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJorW1Gtppie",
        "outputId": "597d7776-3714-4fb3-e962-6f59f66338f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fp-dataset-artifacts'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 36 (delta 2), reused 8 (delta 1), pack-reused 25\u001b[K\n",
            "Receiving objects: 100% (36/36), 17.16 KiB | 2.14 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gregdurrett/fp-dataset-artifacts.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd fp-dataset-artifacts/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFZ11XwHp3dn",
        "outputId": "beb1ed20-c0ca-4315-87f0-454a4365214f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fp-dataset-artifacts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUP1rkKZp7d3",
        "outputId": "c5f763b5-503a-4abf-9363-e3c309c024e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZDRRm98p9hp",
        "outputId": "d1f93368-19a4-4125-d052-95ea0d52ef8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.24.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.66.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.35.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.19.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (0.5)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->-r requirements.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (3.8.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 3)) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->-r requirements.txt (line 2)) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 run.py --do_train --task nli --dataset snli-mccoy-combined-train-shuffle.jsonl --output_dir ./trained_model_combined/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0CJqwQTqPQh",
        "outputId": "6e399424-2a49-4882-830e-3e8976e0b220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 16:36:14.723205: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-11 16:36:14.723267: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-11 16:36:14.723312: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-11 16:36:16.564744: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 9799.78it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1105.80it/s]\n",
            "Generating train split: 568152 examples [00:00, 742954.32 examples/s]\n",
            "Downloading (…)lve/main/config.json: 100% 665/665 [00:00<00:00, 3.52MB/s]\n",
            "Downloading pytorch_model.bin: 100% 54.2M/54.2M [00:00<00:00, 332MB/s]\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Downloading (…)okenizer_config.json: 100% 29.0/29.0 [00:00<00:00, 157kB/s]\n",
            "Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 2.78MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 466k/466k [00:00<00:00, 5.67MB/s]\n",
            "Preprocessing data... (this takes a little bit, should only happen once per dataset)\n",
            "Map (num_proc=2): 100% 568152/568152 [01:45<00:00, 5382.50 examples/s]\n",
            "  0% 0/213057 [00:00<?, ?it/s]You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.9215, 'learning_rate': 4.988266050869016e-05, 'epoch': 0.01}\n",
            "{'loss': 0.7366, 'learning_rate': 4.976532101738033e-05, 'epoch': 0.01}\n",
            "{'loss': 0.6661, 'learning_rate': 4.964798152607049e-05, 'epoch': 0.02}\n",
            "{'loss': 0.6525, 'learning_rate': 4.953064203476066e-05, 'epoch': 0.03}\n",
            "{'loss': 0.6508, 'learning_rate': 4.941330254345082e-05, 'epoch': 0.04}\n",
            "{'loss': 0.6294, 'learning_rate': 4.929596305214098e-05, 'epoch': 0.04}\n",
            "{'loss': 0.5886, 'learning_rate': 4.9178623560831146e-05, 'epoch': 0.05}\n",
            "{'loss': 0.5853, 'learning_rate': 4.90612840695213e-05, 'epoch': 0.06}\n",
            "{'loss': 0.6076, 'learning_rate': 4.894394457821147e-05, 'epoch': 0.06}\n",
            "{'loss': 0.5804, 'learning_rate': 4.882660508690163e-05, 'epoch': 0.07}\n",
            "{'loss': 0.5921, 'learning_rate': 4.870926559559179e-05, 'epoch': 0.08}\n",
            "{'loss': 0.5635, 'learning_rate': 4.8591926104281956e-05, 'epoch': 0.08}\n",
            "{'loss': 0.5894, 'learning_rate': 4.8474586612972116e-05, 'epoch': 0.09}\n",
            "{'loss': 0.5673, 'learning_rate': 4.8357247121662283e-05, 'epoch': 0.1}\n",
            "{'loss': 0.5567, 'learning_rate': 4.8239907630352444e-05, 'epoch': 0.11}\n",
            "{'loss': 0.5544, 'learning_rate': 4.8122568139042604e-05, 'epoch': 0.11}\n",
            "{'loss': 0.5558, 'learning_rate': 4.800522864773277e-05, 'epoch': 0.12}\n",
            "{'loss': 0.5612, 'learning_rate': 4.788788915642293e-05, 'epoch': 0.13}\n",
            "{'loss': 0.5524, 'learning_rate': 4.777054966511309e-05, 'epoch': 0.13}\n",
            "{'loss': 0.5398, 'learning_rate': 4.765321017380326e-05, 'epoch': 0.14}\n",
            "{'loss': 0.5415, 'learning_rate': 4.753587068249342e-05, 'epoch': 0.15}\n",
            "{'loss': 0.5459, 'learning_rate': 4.741853119118359e-05, 'epoch': 0.15}\n",
            "{'loss': 0.5234, 'learning_rate': 4.730119169987374e-05, 'epoch': 0.16}\n",
            "{'loss': 0.5172, 'learning_rate': 4.718385220856391e-05, 'epoch': 0.17}\n",
            "{'loss': 0.5312, 'learning_rate': 4.706651271725407e-05, 'epoch': 0.18}\n",
            "{'loss': 0.5112, 'learning_rate': 4.694917322594423e-05, 'epoch': 0.18}\n",
            "{'loss': 0.5111, 'learning_rate': 4.68318337346344e-05, 'epoch': 0.19}\n",
            "{'loss': 0.5136, 'learning_rate': 4.671449424332456e-05, 'epoch': 0.2}\n",
            "{'loss': 0.5065, 'learning_rate': 4.659715475201472e-05, 'epoch': 0.2}\n",
            "{'loss': 0.498, 'learning_rate': 4.6479815260704886e-05, 'epoch': 0.21}\n",
            "{'loss': 0.5168, 'learning_rate': 4.6362475769395046e-05, 'epoch': 0.22}\n",
            "{'loss': 0.5068, 'learning_rate': 4.624513627808521e-05, 'epoch': 0.23}\n",
            "{'loss': 0.5245, 'learning_rate': 4.6127796786775374e-05, 'epoch': 0.23}\n",
            "{'loss': 0.5035, 'learning_rate': 4.6010457295465534e-05, 'epoch': 0.24}\n",
            "{'loss': 0.503, 'learning_rate': 4.58931178041557e-05, 'epoch': 0.25}\n",
            "{'loss': 0.5086, 'learning_rate': 4.577577831284586e-05, 'epoch': 0.25}\n",
            "{'loss': 0.5072, 'learning_rate': 4.565843882153602e-05, 'epoch': 0.26}\n",
            "{'loss': 0.4815, 'learning_rate': 4.554109933022618e-05, 'epoch': 0.27}\n",
            "{'loss': 0.5067, 'learning_rate': 4.5423759838916344e-05, 'epoch': 0.27}\n",
            "{'loss': 0.5015, 'learning_rate': 4.530642034760651e-05, 'epoch': 0.28}\n",
            "{'loss': 0.4992, 'learning_rate': 4.518908085629667e-05, 'epoch': 0.29}\n",
            "{'loss': 0.4938, 'learning_rate': 4.507174136498684e-05, 'epoch': 0.3}\n",
            "{'loss': 0.5062, 'learning_rate': 4.4954401873677e-05, 'epoch': 0.3}\n",
            "{'loss': 0.4864, 'learning_rate': 4.483706238236716e-05, 'epoch': 0.31}\n",
            "{'loss': 0.4939, 'learning_rate': 4.471972289105733e-05, 'epoch': 0.32}\n",
            "{'loss': 0.4851, 'learning_rate': 4.460238339974749e-05, 'epoch': 0.32}\n",
            "{'loss': 0.4815, 'learning_rate': 4.448504390843765e-05, 'epoch': 0.33}\n",
            "{'loss': 0.4935, 'learning_rate': 4.4367704417127815e-05, 'epoch': 0.34}\n",
            "{'loss': 0.5029, 'learning_rate': 4.4250364925817976e-05, 'epoch': 0.34}\n",
            "{'loss': 0.4866, 'learning_rate': 4.413302543450814e-05, 'epoch': 0.35}\n",
            "{'loss': 0.4719, 'learning_rate': 4.4015685943198304e-05, 'epoch': 0.36}\n",
            "{'loss': 0.4713, 'learning_rate': 4.3898346451888464e-05, 'epoch': 0.37}\n",
            "{'loss': 0.4825, 'learning_rate': 4.3781006960578625e-05, 'epoch': 0.37}\n",
            "{'loss': 0.4632, 'learning_rate': 4.3663667469268785e-05, 'epoch': 0.38}\n",
            "{'loss': 0.4929, 'learning_rate': 4.354632797795895e-05, 'epoch': 0.39}\n",
            "{'loss': 0.4539, 'learning_rate': 4.342898848664911e-05, 'epoch': 0.39}\n",
            "{'loss': 0.4803, 'learning_rate': 4.3311648995339274e-05, 'epoch': 0.4}\n",
            "{'loss': 0.4938, 'learning_rate': 4.319430950402944e-05, 'epoch': 0.41}\n",
            "{'loss': 0.4623, 'learning_rate': 4.30769700127196e-05, 'epoch': 0.42}\n",
            "{'loss': 0.4485, 'learning_rate': 4.295963052140977e-05, 'epoch': 0.42}\n",
            "{'loss': 0.4692, 'learning_rate': 4.284229103009993e-05, 'epoch': 0.43}\n",
            "{'loss': 0.4693, 'learning_rate': 4.272495153879009e-05, 'epoch': 0.44}\n",
            "{'loss': 0.4742, 'learning_rate': 4.260761204748026e-05, 'epoch': 0.44}\n",
            "{'loss': 0.4764, 'learning_rate': 4.249027255617042e-05, 'epoch': 0.45}\n",
            "{'loss': 0.4637, 'learning_rate': 4.2372933064860585e-05, 'epoch': 0.46}\n",
            "{'loss': 0.4745, 'learning_rate': 4.2255593573550745e-05, 'epoch': 0.46}\n",
            "{'loss': 0.4671, 'learning_rate': 4.21382540822409e-05, 'epoch': 0.47}\n",
            "{'loss': 0.4818, 'learning_rate': 4.2020914590931066e-05, 'epoch': 0.48}\n",
            "{'loss': 0.4523, 'learning_rate': 4.190357509962123e-05, 'epoch': 0.49}\n",
            "{'loss': 0.4607, 'learning_rate': 4.1786235608311394e-05, 'epoch': 0.49}\n",
            "{'loss': 0.4561, 'learning_rate': 4.1668896117001555e-05, 'epoch': 0.5}\n",
            "{'loss': 0.4745, 'learning_rate': 4.1551556625691715e-05, 'epoch': 0.51}\n",
            "{'loss': 0.4637, 'learning_rate': 4.143421713438188e-05, 'epoch': 0.51}\n",
            "{'loss': 0.4728, 'learning_rate': 4.131687764307204e-05, 'epoch': 0.52}\n",
            "{'loss': 0.4544, 'learning_rate': 4.119953815176221e-05, 'epoch': 0.53}\n",
            "{'loss': 0.4455, 'learning_rate': 4.108219866045237e-05, 'epoch': 0.54}\n",
            "{'loss': 0.4574, 'learning_rate': 4.096485916914253e-05, 'epoch': 0.54}\n",
            "{'loss': 0.457, 'learning_rate': 4.08475196778327e-05, 'epoch': 0.55}\n",
            "{'loss': 0.454, 'learning_rate': 4.073018018652286e-05, 'epoch': 0.56}\n",
            "{'loss': 0.4481, 'learning_rate': 4.061284069521302e-05, 'epoch': 0.56}\n",
            "{'loss': 0.4736, 'learning_rate': 4.049550120390318e-05, 'epoch': 0.57}\n",
            "{'loss': 0.4462, 'learning_rate': 4.037816171259334e-05, 'epoch': 0.58}\n",
            "{'loss': 0.4565, 'learning_rate': 4.026082222128351e-05, 'epoch': 0.58}\n",
            "{'loss': 0.4522, 'learning_rate': 4.014348272997367e-05, 'epoch': 0.59}\n",
            "{'loss': 0.4484, 'learning_rate': 4.0026143238663836e-05, 'epoch': 0.6}\n",
            "{'loss': 0.4786, 'learning_rate': 3.9908803747353996e-05, 'epoch': 0.61}\n",
            "{'loss': 0.4606, 'learning_rate': 3.979146425604416e-05, 'epoch': 0.61}\n",
            "{'loss': 0.4743, 'learning_rate': 3.9674124764734324e-05, 'epoch': 0.62}\n",
            "{'loss': 0.4634, 'learning_rate': 3.9556785273424485e-05, 'epoch': 0.63}\n",
            "{'loss': 0.4569, 'learning_rate': 3.9439445782114645e-05, 'epoch': 0.63}\n",
            "{'loss': 0.4493, 'learning_rate': 3.932210629080481e-05, 'epoch': 0.64}\n",
            "{'loss': 0.4464, 'learning_rate': 3.920476679949497e-05, 'epoch': 0.65}\n",
            "{'loss': 0.4234, 'learning_rate': 3.908742730818514e-05, 'epoch': 0.65}\n",
            "{'loss': 0.4774, 'learning_rate': 3.89700878168753e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4741, 'learning_rate': 3.885274832556546e-05, 'epoch': 0.67}\n",
            "{'loss': 0.4408, 'learning_rate': 3.873540883425562e-05, 'epoch': 0.68}\n",
            "{'loss': 0.4554, 'learning_rate': 3.861806934294578e-05, 'epoch': 0.68}\n",
            "{'loss': 0.4376, 'learning_rate': 3.850072985163595e-05, 'epoch': 0.69}\n",
            "{'loss': 0.4333, 'learning_rate': 3.838339036032611e-05, 'epoch': 0.7}\n",
            "{'loss': 0.4389, 'learning_rate': 3.826605086901627e-05, 'epoch': 0.7}\n",
            "{'loss': 0.4454, 'learning_rate': 3.814871137770644e-05, 'epoch': 0.71}\n",
            "{'loss': 0.4422, 'learning_rate': 3.80313718863966e-05, 'epoch': 0.72}\n",
            "{'loss': 0.4371, 'learning_rate': 3.7914032395086766e-05, 'epoch': 0.73}\n",
            "{'loss': 0.4451, 'learning_rate': 3.7796692903776926e-05, 'epoch': 0.73}\n",
            "{'loss': 0.4437, 'learning_rate': 3.7679353412467087e-05, 'epoch': 0.74}\n",
            "{'loss': 0.4591, 'learning_rate': 3.7562013921157254e-05, 'epoch': 0.75}\n",
            "{'loss': 0.4227, 'learning_rate': 3.7444674429847414e-05, 'epoch': 0.75}\n",
            "{'loss': 0.4409, 'learning_rate': 3.7327334938537575e-05, 'epoch': 0.76}\n",
            "{'loss': 0.4659, 'learning_rate': 3.720999544722774e-05, 'epoch': 0.77}\n",
            "{'loss': 0.4341, 'learning_rate': 3.70926559559179e-05, 'epoch': 0.77}\n",
            "{'loss': 0.4291, 'learning_rate': 3.697531646460806e-05, 'epoch': 0.78}\n",
            "{'loss': 0.4453, 'learning_rate': 3.6857976973298224e-05, 'epoch': 0.79}\n",
            "{'loss': 0.4578, 'learning_rate': 3.674063748198839e-05, 'epoch': 0.8}\n",
            "{'loss': 0.4389, 'learning_rate': 3.662329799067855e-05, 'epoch': 0.8}\n",
            "{'loss': 0.4285, 'learning_rate': 3.650595849936871e-05, 'epoch': 0.81}\n",
            "{'loss': 0.4153, 'learning_rate': 3.638861900805888e-05, 'epoch': 0.82}\n",
            "{'loss': 0.4425, 'learning_rate': 3.627127951674904e-05, 'epoch': 0.82}\n",
            "{'loss': 0.4421, 'learning_rate': 3.61539400254392e-05, 'epoch': 0.83}\n",
            "{'loss': 0.4387, 'learning_rate': 3.603660053412937e-05, 'epoch': 0.84}\n",
            "{'loss': 0.4294, 'learning_rate': 3.591926104281953e-05, 'epoch': 0.84}\n",
            "{'loss': 0.4569, 'learning_rate': 3.5801921551509695e-05, 'epoch': 0.85}\n",
            "{'loss': 0.4397, 'learning_rate': 3.5684582060199856e-05, 'epoch': 0.86}\n",
            "{'loss': 0.4459, 'learning_rate': 3.5567242568890016e-05, 'epoch': 0.87}\n",
            "{'loss': 0.4411, 'learning_rate': 3.5449903077580184e-05, 'epoch': 0.87}\n",
            "{'loss': 0.4268, 'learning_rate': 3.5332563586270344e-05, 'epoch': 0.88}\n",
            "{'loss': 0.4241, 'learning_rate': 3.5215224094960505e-05, 'epoch': 0.89}\n",
            "{'loss': 0.4191, 'learning_rate': 3.5097884603650665e-05, 'epoch': 0.89}\n",
            "{'loss': 0.4461, 'learning_rate': 3.4980545112340826e-05, 'epoch': 0.9}\n",
            "{'loss': 0.4139, 'learning_rate': 3.486320562103099e-05, 'epoch': 0.91}\n",
            "{'loss': 0.4378, 'learning_rate': 3.4745866129721154e-05, 'epoch': 0.92}\n",
            "{'loss': 0.4432, 'learning_rate': 3.462852663841132e-05, 'epoch': 0.92}\n",
            "{'loss': 0.4401, 'learning_rate': 3.451118714710148e-05, 'epoch': 0.93}\n",
            "{'loss': 0.4409, 'learning_rate': 3.439384765579164e-05, 'epoch': 0.94}\n",
            "{'loss': 0.4264, 'learning_rate': 3.427650816448181e-05, 'epoch': 0.94}\n",
            "{'loss': 0.4256, 'learning_rate': 3.415916867317197e-05, 'epoch': 0.95}\n",
            "{'loss': 0.4246, 'learning_rate': 3.404182918186214e-05, 'epoch': 0.96}\n",
            "{'loss': 0.4086, 'learning_rate': 3.39244896905523e-05, 'epoch': 0.96}\n",
            "{'loss': 0.4353, 'learning_rate': 3.380715019924246e-05, 'epoch': 0.97}\n",
            "{'loss': 0.4092, 'learning_rate': 3.3689810707932625e-05, 'epoch': 0.98}\n",
            "{'loss': 0.4408, 'learning_rate': 3.357247121662278e-05, 'epoch': 0.99}\n",
            "{'loss': 0.4202, 'learning_rate': 3.3455131725312946e-05, 'epoch': 0.99}\n",
            "{'loss': 0.4199, 'learning_rate': 3.333779223400311e-05, 'epoch': 1.0}\n",
            "{'loss': 0.4072, 'learning_rate': 3.322045274269327e-05, 'epoch': 1.01}\n",
            "{'loss': 0.4083, 'learning_rate': 3.3103113251383435e-05, 'epoch': 1.01}\n",
            "{'loss': 0.3991, 'learning_rate': 3.2985773760073595e-05, 'epoch': 1.02}\n",
            "{'loss': 0.3915, 'learning_rate': 3.286843426876376e-05, 'epoch': 1.03}\n",
            "{'loss': 0.3975, 'learning_rate': 3.275109477745392e-05, 'epoch': 1.03}\n",
            "{'loss': 0.3709, 'learning_rate': 3.2633755286144083e-05, 'epoch': 1.04}\n",
            "{'loss': 0.4225, 'learning_rate': 3.251641579483425e-05, 'epoch': 1.05}\n",
            "{'loss': 0.3965, 'learning_rate': 3.239907630352441e-05, 'epoch': 1.06}\n",
            "{'loss': 0.3839, 'learning_rate': 3.228173681221457e-05, 'epoch': 1.06}\n",
            "{'loss': 0.3947, 'learning_rate': 3.216439732090474e-05, 'epoch': 1.07}\n",
            "{'loss': 0.3989, 'learning_rate': 3.20470578295949e-05, 'epoch': 1.08}\n",
            "{'loss': 0.3905, 'learning_rate': 3.192971833828507e-05, 'epoch': 1.08}\n",
            "{'loss': 0.4075, 'learning_rate': 3.181237884697522e-05, 'epoch': 1.09}\n",
            "{'loss': 0.3844, 'learning_rate': 3.169503935566539e-05, 'epoch': 1.1}\n",
            "{'loss': 0.401, 'learning_rate': 3.157769986435555e-05, 'epoch': 1.11}\n",
            "{'loss': 0.4022, 'learning_rate': 3.146036037304571e-05, 'epoch': 1.11}\n",
            "{'loss': 0.3869, 'learning_rate': 3.1343020881735876e-05, 'epoch': 1.12}\n",
            "{'loss': 0.3967, 'learning_rate': 3.122568139042604e-05, 'epoch': 1.13}\n",
            "{'loss': 0.4052, 'learning_rate': 3.11083418991162e-05, 'epoch': 1.13}\n",
            "{'loss': 0.3898, 'learning_rate': 3.0991002407806365e-05, 'epoch': 1.14}\n",
            "{'loss': 0.4166, 'learning_rate': 3.0873662916496525e-05, 'epoch': 1.15}\n",
            "{'loss': 0.4046, 'learning_rate': 3.075632342518669e-05, 'epoch': 1.15}\n",
            "{'loss': 0.3986, 'learning_rate': 3.063898393387685e-05, 'epoch': 1.16}\n",
            "{'loss': 0.4041, 'learning_rate': 3.052164444256701e-05, 'epoch': 1.17}\n",
            "{'loss': 0.3927, 'learning_rate': 3.0404304951257177e-05, 'epoch': 1.18}\n",
            "{'loss': 0.4029, 'learning_rate': 3.028696545994734e-05, 'epoch': 1.18}\n",
            "{'loss': 0.3962, 'learning_rate': 3.0169625968637505e-05, 'epoch': 1.19}\n",
            "{'loss': 0.3925, 'learning_rate': 3.0052286477327662e-05, 'epoch': 1.2}\n",
            "{'loss': 0.4112, 'learning_rate': 2.9934946986017826e-05, 'epoch': 1.2}\n",
            "{'loss': 0.3985, 'learning_rate': 2.981760749470799e-05, 'epoch': 1.21}\n",
            "{'loss': 0.407, 'learning_rate': 2.970026800339815e-05, 'epoch': 1.22}\n",
            "{'loss': 0.4197, 'learning_rate': 2.9582928512088314e-05, 'epoch': 1.23}\n",
            "{'loss': 0.3937, 'learning_rate': 2.946558902077848e-05, 'epoch': 1.23}\n",
            "{'loss': 0.3993, 'learning_rate': 2.9348249529468642e-05, 'epoch': 1.24}\n",
            "{'loss': 0.3993, 'learning_rate': 2.9230910038158803e-05, 'epoch': 1.25}\n",
            "{'loss': 0.3931, 'learning_rate': 2.9113570546848967e-05, 'epoch': 1.25}\n",
            "{'loss': 0.4072, 'learning_rate': 2.899623105553913e-05, 'epoch': 1.26}\n",
            "{'loss': 0.4105, 'learning_rate': 2.8878891564229294e-05, 'epoch': 1.27}\n",
            "{'loss': 0.4038, 'learning_rate': 2.8761552072919455e-05, 'epoch': 1.27}\n",
            "{'loss': 0.4072, 'learning_rate': 2.864421258160962e-05, 'epoch': 1.28}\n",
            "{'loss': 0.3911, 'learning_rate': 2.8526873090299783e-05, 'epoch': 1.29}\n",
            "{'loss': 0.3894, 'learning_rate': 2.840953359898994e-05, 'epoch': 1.3}\n",
            "{'loss': 0.3955, 'learning_rate': 2.8292194107680104e-05, 'epoch': 1.3}\n",
            "{'loss': 0.4009, 'learning_rate': 2.8174854616370268e-05, 'epoch': 1.31}\n",
            "{'loss': 0.3842, 'learning_rate': 2.8057515125060428e-05, 'epoch': 1.32}\n",
            "{'loss': 0.4037, 'learning_rate': 2.7940175633750592e-05, 'epoch': 1.32}\n",
            "{'loss': 0.389, 'learning_rate': 2.7822836142440756e-05, 'epoch': 1.33}\n",
            "{'loss': 0.3907, 'learning_rate': 2.770549665113092e-05, 'epoch': 1.34}\n",
            "{'loss': 0.395, 'learning_rate': 2.758815715982108e-05, 'epoch': 1.34}\n",
            "{'loss': 0.3937, 'learning_rate': 2.7470817668511244e-05, 'epoch': 1.35}\n",
            "{'loss': 0.4109, 'learning_rate': 2.7353478177201408e-05, 'epoch': 1.36}\n",
            "{'loss': 0.4036, 'learning_rate': 2.7236138685891572e-05, 'epoch': 1.37}\n",
            "{'loss': 0.4082, 'learning_rate': 2.7118799194581736e-05, 'epoch': 1.37}\n",
            "{'loss': 0.3909, 'learning_rate': 2.7001459703271897e-05, 'epoch': 1.38}\n",
            "{'loss': 0.3964, 'learning_rate': 2.688412021196206e-05, 'epoch': 1.39}\n",
            "{'loss': 0.3803, 'learning_rate': 2.6766780720652224e-05, 'epoch': 1.39}\n",
            "{'loss': 0.3999, 'learning_rate': 2.664944122934238e-05, 'epoch': 1.4}\n",
            "{'loss': 0.3884, 'learning_rate': 2.6532101738032545e-05, 'epoch': 1.41}\n",
            "{'loss': 0.3876, 'learning_rate': 2.6414762246722706e-05, 'epoch': 1.42}\n",
            "{'loss': 0.3947, 'learning_rate': 2.629742275541287e-05, 'epoch': 1.42}\n",
            "{'loss': 0.4117, 'learning_rate': 2.6180083264103034e-05, 'epoch': 1.43}\n",
            "{'loss': 0.3777, 'learning_rate': 2.6062743772793198e-05, 'epoch': 1.44}\n",
            "{'loss': 0.3827, 'learning_rate': 2.594540428148336e-05, 'epoch': 1.44}\n",
            "{'loss': 0.3979, 'learning_rate': 2.5828064790173522e-05, 'epoch': 1.45}\n",
            "{'loss': 0.4036, 'learning_rate': 2.5710725298863686e-05, 'epoch': 1.46}\n",
            "{'loss': 0.3911, 'learning_rate': 2.559338580755385e-05, 'epoch': 1.46}\n",
            "{'loss': 0.405, 'learning_rate': 2.5476046316244014e-05, 'epoch': 1.47}\n",
            "{'loss': 0.3856, 'learning_rate': 2.5358706824934174e-05, 'epoch': 1.48}\n",
            "{'loss': 0.3866, 'learning_rate': 2.5241367333624338e-05, 'epoch': 1.49}\n",
            "{'loss': 0.4054, 'learning_rate': 2.5124027842314502e-05, 'epoch': 1.49}\n",
            "{'loss': 0.3826, 'learning_rate': 2.5006688351004666e-05, 'epoch': 1.5}\n",
            "{'loss': 0.3999, 'learning_rate': 2.4889348859694826e-05, 'epoch': 1.51}\n",
            "{'loss': 0.3898, 'learning_rate': 2.4772009368384987e-05, 'epoch': 1.51}\n",
            "{'loss': 0.3941, 'learning_rate': 2.465466987707515e-05, 'epoch': 1.52}\n",
            "{'loss': 0.3895, 'learning_rate': 2.4537330385765315e-05, 'epoch': 1.53}\n",
            "{'loss': 0.3974, 'learning_rate': 2.4419990894455475e-05, 'epoch': 1.53}\n",
            "{'loss': 0.374, 'learning_rate': 2.430265140314564e-05, 'epoch': 1.54}\n",
            "{'loss': 0.4178, 'learning_rate': 2.41853119118358e-05, 'epoch': 1.55}\n",
            "{'loss': 0.3916, 'learning_rate': 2.4067972420525964e-05, 'epoch': 1.56}\n",
            "{'loss': 0.3994, 'learning_rate': 2.3950632929216127e-05, 'epoch': 1.56}\n",
            "{'loss': 0.3816, 'learning_rate': 2.383329343790629e-05, 'epoch': 1.57}\n",
            "{'loss': 0.39, 'learning_rate': 2.3715953946596452e-05, 'epoch': 1.58}\n",
            "{'loss': 0.3866, 'learning_rate': 2.3598614455286612e-05, 'epoch': 1.58}\n",
            "{'loss': 0.3826, 'learning_rate': 2.3481274963976776e-05, 'epoch': 1.59}\n",
            "{'loss': 0.4003, 'learning_rate': 2.336393547266694e-05, 'epoch': 1.6}\n",
            "{'loss': 0.367, 'learning_rate': 2.3246595981357104e-05, 'epoch': 1.61}\n",
            "{'loss': 0.4108, 'learning_rate': 2.3129256490047265e-05, 'epoch': 1.61}\n",
            "{'loss': 0.3713, 'learning_rate': 2.301191699873743e-05, 'epoch': 1.62}\n",
            "{'loss': 0.3849, 'learning_rate': 2.2894577507427592e-05, 'epoch': 1.63}\n",
            "{'loss': 0.3659, 'learning_rate': 2.2777238016117753e-05, 'epoch': 1.63}\n",
            "{'loss': 0.3972, 'learning_rate': 2.2659898524807917e-05, 'epoch': 1.64}\n",
            "{'loss': 0.4015, 'learning_rate': 2.2542559033498077e-05, 'epoch': 1.65}\n",
            "{'loss': 0.3869, 'learning_rate': 2.242521954218824e-05, 'epoch': 1.65}\n",
            "{'loss': 0.3997, 'learning_rate': 2.2307880050878405e-05, 'epoch': 1.66}\n",
            "{'loss': 0.3799, 'learning_rate': 2.219054055956857e-05, 'epoch': 1.67}\n",
            "{'loss': 0.37, 'learning_rate': 2.207320106825873e-05, 'epoch': 1.68}\n",
            "{'loss': 0.395, 'learning_rate': 2.1955861576948893e-05, 'epoch': 1.68}\n",
            "{'loss': 0.3951, 'learning_rate': 2.1838522085639054e-05, 'epoch': 1.69}\n",
            "{'loss': 0.3943, 'learning_rate': 2.1721182594329218e-05, 'epoch': 1.7}\n",
            "{'loss': 0.3902, 'learning_rate': 2.1603843103019382e-05, 'epoch': 1.7}\n",
            "{'loss': 0.3844, 'learning_rate': 2.1486503611709542e-05, 'epoch': 1.71}\n",
            "{'loss': 0.3905, 'learning_rate': 2.1369164120399706e-05, 'epoch': 1.72}\n",
            "{'loss': 0.3895, 'learning_rate': 2.125182462908987e-05, 'epoch': 1.72}\n",
            "{'loss': 0.3801, 'learning_rate': 2.1134485137780034e-05, 'epoch': 1.73}\n",
            "{'loss': 0.3993, 'learning_rate': 2.1017145646470194e-05, 'epoch': 1.74}\n",
            "{'loss': 0.3805, 'learning_rate': 2.0899806155160355e-05, 'epoch': 1.75}\n",
            "{'loss': 0.3794, 'learning_rate': 2.078246666385052e-05, 'epoch': 1.75}\n",
            "{'loss': 0.3835, 'learning_rate': 2.0665127172540683e-05, 'epoch': 1.76}\n",
            "{'loss': 0.3786, 'learning_rate': 2.0547787681230847e-05, 'epoch': 1.77}\n",
            "{'loss': 0.3937, 'learning_rate': 2.0430448189921007e-05, 'epoch': 1.77}\n",
            "{'loss': 0.4012, 'learning_rate': 2.031310869861117e-05, 'epoch': 1.78}\n",
            "{'loss': 0.4006, 'learning_rate': 2.019576920730133e-05, 'epoch': 1.79}\n",
            "{'loss': 0.3917, 'learning_rate': 2.0078429715991495e-05, 'epoch': 1.8}\n",
            "{'loss': 0.3961, 'learning_rate': 1.996109022468166e-05, 'epoch': 1.8}\n",
            "{'loss': 0.3902, 'learning_rate': 1.984375073337182e-05, 'epoch': 1.81}\n",
            "{'loss': 0.3717, 'learning_rate': 1.9726411242061984e-05, 'epoch': 1.82}\n",
            "{'loss': 0.407, 'learning_rate': 1.9609071750752148e-05, 'epoch': 1.82}\n",
            "{'loss': 0.4103, 'learning_rate': 1.949173225944231e-05, 'epoch': 1.83}\n",
            "{'loss': 0.3803, 'learning_rate': 1.9374392768132476e-05, 'epoch': 1.84}\n",
            "{'loss': 0.3967, 'learning_rate': 1.9257053276822633e-05, 'epoch': 1.84}\n",
            "{'loss': 0.368, 'learning_rate': 1.9139713785512797e-05, 'epoch': 1.85}\n",
            "{'loss': 0.3774, 'learning_rate': 1.902237429420296e-05, 'epoch': 1.86}\n",
            "{'loss': 0.3899, 'learning_rate': 1.8905034802893124e-05, 'epoch': 1.87}\n",
            "{'loss': 0.3864, 'learning_rate': 1.8787695311583288e-05, 'epoch': 1.87}\n",
            "{'loss': 0.3866, 'learning_rate': 1.867035582027345e-05, 'epoch': 1.88}\n",
            "{'loss': 0.3732, 'learning_rate': 1.8553016328963613e-05, 'epoch': 1.89}\n",
            "{'loss': 0.3665, 'learning_rate': 1.8435676837653773e-05, 'epoch': 1.89}\n",
            "{'loss': 0.3707, 'learning_rate': 1.8318337346343937e-05, 'epoch': 1.9}\n",
            "{'loss': 0.3981, 'learning_rate': 1.82009978550341e-05, 'epoch': 1.91}\n",
            "{'loss': 0.3851, 'learning_rate': 1.808365836372426e-05, 'epoch': 1.91}\n",
            "{'loss': 0.3721, 'learning_rate': 1.7966318872414425e-05, 'epoch': 1.92}\n",
            "{'loss': 0.3889, 'learning_rate': 1.784897938110459e-05, 'epoch': 1.93}\n",
            "{'loss': 0.4004, 'learning_rate': 1.7731639889794753e-05, 'epoch': 1.94}\n",
            "{'loss': 0.3617, 'learning_rate': 1.761430039848491e-05, 'epoch': 1.94}\n",
            "{'loss': 0.3959, 'learning_rate': 1.7496960907175074e-05, 'epoch': 1.95}\n",
            "{'loss': 0.3924, 'learning_rate': 1.7379621415865238e-05, 'epoch': 1.96}\n",
            "{'loss': 0.3682, 'learning_rate': 1.7262281924555402e-05, 'epoch': 1.96}\n",
            "{'loss': 0.3768, 'learning_rate': 1.7144942433245566e-05, 'epoch': 1.97}\n",
            "{'loss': 0.3663, 'learning_rate': 1.7027602941935726e-05, 'epoch': 1.98}\n",
            "{'loss': 0.3679, 'learning_rate': 1.691026345062589e-05, 'epoch': 1.99}\n",
            "{'loss': 0.3772, 'learning_rate': 1.6792923959316054e-05, 'epoch': 1.99}\n",
            "{'loss': 0.3818, 'learning_rate': 1.6675584468006215e-05, 'epoch': 2.0}\n",
            "{'loss': 0.3341, 'learning_rate': 1.655824497669638e-05, 'epoch': 2.01}\n",
            "{'loss': 0.3821, 'learning_rate': 1.644090548538654e-05, 'epoch': 2.01}\n",
            "{'loss': 0.3332, 'learning_rate': 1.6323565994076703e-05, 'epoch': 2.02}\n",
            "{'loss': 0.3263, 'learning_rate': 1.6206226502766867e-05, 'epoch': 2.03}\n",
            "{'loss': 0.3705, 'learning_rate': 1.608888701145703e-05, 'epoch': 2.03}\n",
            "{'loss': 0.3442, 'learning_rate': 1.597154752014719e-05, 'epoch': 2.04}\n",
            "{'loss': 0.3491, 'learning_rate': 1.5854208028837352e-05, 'epoch': 2.05}\n",
            "{'loss': 0.3548, 'learning_rate': 1.5736868537527516e-05, 'epoch': 2.06}\n",
            "{'loss': 0.352, 'learning_rate': 1.561952904621768e-05, 'epoch': 2.06}\n",
            "{'loss': 0.3666, 'learning_rate': 1.5502189554907844e-05, 'epoch': 2.07}\n",
            "{'loss': 0.3377, 'learning_rate': 1.5384850063598004e-05, 'epoch': 2.08}\n",
            "{'loss': 0.3288, 'learning_rate': 1.5267510572288168e-05, 'epoch': 2.08}\n",
            "{'loss': 0.3582, 'learning_rate': 1.5150171080978332e-05, 'epoch': 2.09}\n",
            "{'loss': 0.3686, 'learning_rate': 1.5032831589668492e-05, 'epoch': 2.1}\n",
            "{'loss': 0.3599, 'learning_rate': 1.4915492098358655e-05, 'epoch': 2.11}\n",
            "{'loss': 0.3451, 'learning_rate': 1.4798152607048818e-05, 'epoch': 2.11}\n",
            "{'loss': 0.353, 'learning_rate': 1.468081311573898e-05, 'epoch': 2.12}\n",
            "{'loss': 0.3365, 'learning_rate': 1.4563473624429145e-05, 'epoch': 2.13}\n",
            "{'loss': 0.3551, 'learning_rate': 1.4446134133119307e-05, 'epoch': 2.13}\n",
            "{'loss': 0.3564, 'learning_rate': 1.432879464180947e-05, 'epoch': 2.14}\n",
            "{'loss': 0.3441, 'learning_rate': 1.4211455150499633e-05, 'epoch': 2.15}\n",
            "{'loss': 0.366, 'learning_rate': 1.4094115659189793e-05, 'epoch': 2.15}\n",
            "{'loss': 0.3318, 'learning_rate': 1.3976776167879957e-05, 'epoch': 2.16}\n",
            "{'loss': 0.338, 'learning_rate': 1.385943667657012e-05, 'epoch': 2.17}\n",
            "{'loss': 0.362, 'learning_rate': 1.3742097185260283e-05, 'epoch': 2.18}\n",
            "{'loss': 0.349, 'learning_rate': 1.3624757693950446e-05, 'epoch': 2.18}\n",
            "{'loss': 0.3632, 'learning_rate': 1.350741820264061e-05, 'epoch': 2.19}\n",
            "{'loss': 0.3518, 'learning_rate': 1.3390078711330772e-05, 'epoch': 2.2}\n",
            "{'loss': 0.3322, 'learning_rate': 1.3272739220020932e-05, 'epoch': 2.2}\n",
            "{'loss': 0.3311, 'learning_rate': 1.3155399728711096e-05, 'epoch': 2.21}\n",
            "{'loss': 0.3402, 'learning_rate': 1.3038060237401258e-05, 'epoch': 2.22}\n",
            "{'loss': 0.3139, 'learning_rate': 1.2920720746091422e-05, 'epoch': 2.22}\n",
            "{'loss': 0.3864, 'learning_rate': 1.2803381254781584e-05, 'epoch': 2.23}\n",
            "{'loss': 0.3521, 'learning_rate': 1.2686041763471748e-05, 'epoch': 2.24}\n",
            "{'loss': 0.3643, 'learning_rate': 1.256870227216191e-05, 'epoch': 2.25}\n",
            "{'loss': 0.3587, 'learning_rate': 1.2451362780852073e-05, 'epoch': 2.25}\n",
            "{'loss': 0.3677, 'learning_rate': 1.2334023289542237e-05, 'epoch': 2.26}\n",
            "{'loss': 0.3568, 'learning_rate': 1.2216683798232397e-05, 'epoch': 2.27}\n",
            "{'loss': 0.3419, 'learning_rate': 1.2099344306922561e-05, 'epoch': 2.27}\n",
            "{'loss': 0.3716, 'learning_rate': 1.1982004815612723e-05, 'epoch': 2.28}\n",
            "{'loss': 0.3366, 'learning_rate': 1.1864665324302887e-05, 'epoch': 2.29}\n",
            "{'loss': 0.3403, 'learning_rate': 1.174732583299305e-05, 'epoch': 2.3}\n",
            "{'loss': 0.3302, 'learning_rate': 1.1629986341683212e-05, 'epoch': 2.3}\n",
            "{'loss': 0.355, 'learning_rate': 1.1512646850373376e-05, 'epoch': 2.31}\n",
            "{'loss': 0.3442, 'learning_rate': 1.1395307359063538e-05, 'epoch': 2.32}\n",
            "{'loss': 0.3513, 'learning_rate': 1.12779678677537e-05, 'epoch': 2.32}\n",
            "{'loss': 0.3559, 'learning_rate': 1.1160628376443862e-05, 'epoch': 2.33}\n",
            "{'loss': 0.3425, 'learning_rate': 1.1043288885134026e-05, 'epoch': 2.34}\n",
            "{'loss': 0.3521, 'learning_rate': 1.0925949393824188e-05, 'epoch': 2.34}\n",
            "{'loss': 0.3416, 'learning_rate': 1.080860990251435e-05, 'epoch': 2.35}\n",
            "{'loss': 0.3458, 'learning_rate': 1.0691270411204514e-05, 'epoch': 2.36}\n",
            "{'loss': 0.3575, 'learning_rate': 1.0573930919894677e-05, 'epoch': 2.37}\n",
            "{'loss': 0.3404, 'learning_rate': 1.0456591428584839e-05, 'epoch': 2.37}\n",
            "{'loss': 0.364, 'learning_rate': 1.0339251937275003e-05, 'epoch': 2.38}\n",
            "{'loss': 0.3309, 'learning_rate': 1.0221912445965165e-05, 'epoch': 2.39}\n",
            "{'loss': 0.334, 'learning_rate': 1.0104572954655329e-05, 'epoch': 2.39}\n",
            "{'loss': 0.3285, 'learning_rate': 9.98723346334549e-06, 'epoch': 2.4}\n",
            "{'loss': 0.3408, 'learning_rate': 9.869893972035653e-06, 'epoch': 2.41}\n",
            "{'loss': 0.3588, 'learning_rate': 9.752554480725815e-06, 'epoch': 2.41}\n",
            "{'loss': 0.3499, 'learning_rate': 9.635214989415978e-06, 'epoch': 2.42}\n",
            "{'loss': 0.3401, 'learning_rate': 9.517875498106142e-06, 'epoch': 2.43}\n",
            "{'loss': 0.3713, 'learning_rate': 9.400536006796304e-06, 'epoch': 2.44}\n",
            "{'loss': 0.3247, 'learning_rate': 9.283196515486468e-06, 'epoch': 2.44}\n",
            "{'loss': 0.353, 'learning_rate': 9.165857024176628e-06, 'epoch': 2.45}\n",
            "{'loss': 0.3499, 'learning_rate': 9.048517532866792e-06, 'epoch': 2.46}\n",
            "{'loss': 0.3449, 'learning_rate': 8.931178041556954e-06, 'epoch': 2.46}\n",
            "{'loss': 0.3232, 'learning_rate': 8.813838550247118e-06, 'epoch': 2.47}\n",
            "{'loss': 0.3484, 'learning_rate': 8.69649905893728e-06, 'epoch': 2.48}\n",
            "{'loss': 0.3566, 'learning_rate': 8.579159567627443e-06, 'epoch': 2.49}\n",
            "{'loss': 0.3392, 'learning_rate': 8.461820076317606e-06, 'epoch': 2.49}\n",
            "{'loss': 0.3462, 'learning_rate': 8.344480585007767e-06, 'epoch': 2.5}\n",
            "{'loss': 0.3401, 'learning_rate': 8.227141093697931e-06, 'epoch': 2.51}\n",
            "{'loss': 0.3447, 'learning_rate': 8.109801602388093e-06, 'epoch': 2.51}\n",
            "{'loss': 0.3407, 'learning_rate': 7.992462111078257e-06, 'epoch': 2.52}\n",
            "{'loss': 0.3701, 'learning_rate': 7.87512261976842e-06, 'epoch': 2.53}\n",
            "{'loss': 0.3372, 'learning_rate': 7.757783128458581e-06, 'epoch': 2.53}\n",
            "{'loss': 0.3465, 'learning_rate': 7.640443637148745e-06, 'epoch': 2.54}\n",
            "{'loss': 0.3439, 'learning_rate': 7.5231041458389075e-06, 'epoch': 2.55}\n",
            "{'loss': 0.3411, 'learning_rate': 7.40576465452907e-06, 'epoch': 2.56}\n",
            "{'loss': 0.3314, 'learning_rate': 7.288425163219233e-06, 'epoch': 2.56}\n",
            "{'loss': 0.3418, 'learning_rate': 7.171085671909396e-06, 'epoch': 2.57}\n",
            "{'loss': 0.3541, 'learning_rate': 7.053746180599559e-06, 'epoch': 2.58}\n",
            "{'loss': 0.3488, 'learning_rate': 6.93640668928972e-06, 'epoch': 2.58}\n",
            "{'loss': 0.3393, 'learning_rate': 6.819067197979884e-06, 'epoch': 2.59}\n",
            "{'loss': 0.3374, 'learning_rate': 6.701727706670047e-06, 'epoch': 2.6}\n",
            "{'loss': 0.3255, 'learning_rate': 6.5843882153602085e-06, 'epoch': 2.6}\n",
            "{'loss': 0.3117, 'learning_rate': 6.467048724050372e-06, 'epoch': 2.61}\n",
            "{'loss': 0.35, 'learning_rate': 6.349709232740535e-06, 'epoch': 2.62}\n",
            "{'loss': 0.3388, 'learning_rate': 6.232369741430697e-06, 'epoch': 2.63}\n",
            "{'loss': 0.3554, 'learning_rate': 6.11503025012086e-06, 'epoch': 2.63}\n",
            "{'loss': 0.3553, 'learning_rate': 5.997690758811023e-06, 'epoch': 2.64}\n",
            "{'loss': 0.3409, 'learning_rate': 5.880351267501186e-06, 'epoch': 2.65}\n",
            "{'loss': 0.3299, 'learning_rate': 5.763011776191348e-06, 'epoch': 2.65}\n",
            "{'loss': 0.34, 'learning_rate': 5.64567228488151e-06, 'epoch': 2.66}\n",
            "{'loss': 0.3504, 'learning_rate': 5.5283327935716735e-06, 'epoch': 2.67}\n",
            "{'loss': 0.3427, 'learning_rate': 5.410993302261836e-06, 'epoch': 2.68}\n",
            "{'loss': 0.32, 'learning_rate': 5.293653810951999e-06, 'epoch': 2.68}\n",
            "{'loss': 0.3463, 'learning_rate': 5.176314319642162e-06, 'epoch': 2.69}\n",
            "{'loss': 0.3249, 'learning_rate': 5.058974828332325e-06, 'epoch': 2.7}\n",
            "{'loss': 0.3567, 'learning_rate': 4.941635337022487e-06, 'epoch': 2.7}\n",
            "{'loss': 0.3346, 'learning_rate': 4.82429584571265e-06, 'epoch': 2.71}\n",
            "{'loss': 0.3301, 'learning_rate': 4.706956354402812e-06, 'epoch': 2.72}\n",
            "{'loss': 0.3261, 'learning_rate': 4.589616863092975e-06, 'epoch': 2.72}\n",
            "{'loss': 0.3287, 'learning_rate': 4.472277371783138e-06, 'epoch': 2.73}\n",
            "{'loss': 0.3348, 'learning_rate': 4.3549378804733015e-06, 'epoch': 2.74}\n",
            "{'loss': 0.3403, 'learning_rate': 4.237598389163464e-06, 'epoch': 2.75}\n",
            "{'loss': 0.3513, 'learning_rate': 4.120258897853626e-06, 'epoch': 2.75}\n",
            "{'loss': 0.366, 'learning_rate': 4.002919406543789e-06, 'epoch': 2.76}\n",
            "{'loss': 0.3304, 'learning_rate': 3.885579915233951e-06, 'epoch': 2.77}\n",
            "{'loss': 0.3311, 'learning_rate': 3.7682404239241146e-06, 'epoch': 2.77}\n",
            "{'loss': 0.3205, 'learning_rate': 3.650900932614277e-06, 'epoch': 2.78}\n",
            "{'loss': 0.324, 'learning_rate': 3.53356144130444e-06, 'epoch': 2.79}\n",
            "{'loss': 0.3585, 'learning_rate': 3.4162219499946025e-06, 'epoch': 2.8}\n",
            "{'loss': 0.3163, 'learning_rate': 3.2988824586847656e-06, 'epoch': 2.8}\n",
            "{'loss': 0.3526, 'learning_rate': 3.1815429673749278e-06, 'epoch': 2.81}\n",
            "{'loss': 0.3567, 'learning_rate': 3.064203476065091e-06, 'epoch': 2.82}\n",
            "{'loss': 0.322, 'learning_rate': 2.9468639847552534e-06, 'epoch': 2.82}\n",
            "{'loss': 0.3282, 'learning_rate': 2.829524493445416e-06, 'epoch': 2.83}\n",
            "{'loss': 0.3425, 'learning_rate': 2.712185002135579e-06, 'epoch': 2.84}\n",
            "{'loss': 0.3274, 'learning_rate': 2.5948455108257418e-06, 'epoch': 2.84}\n",
            "{'loss': 0.325, 'learning_rate': 2.4775060195159044e-06, 'epoch': 2.85}\n",
            "{'loss': 0.3695, 'learning_rate': 2.360166528206067e-06, 'epoch': 2.86}\n",
            "{'loss': 0.3467, 'learning_rate': 2.2428270368962296e-06, 'epoch': 2.87}\n",
            "{'loss': 0.3277, 'learning_rate': 2.1254875455863923e-06, 'epoch': 2.87}\n",
            "{'loss': 0.3338, 'learning_rate': 2.008148054276555e-06, 'epoch': 2.88}\n",
            "{'loss': 0.3258, 'learning_rate': 1.8908085629667177e-06, 'epoch': 2.89}\n",
            "{'loss': 0.3528, 'learning_rate': 1.7734690716568806e-06, 'epoch': 2.89}\n",
            "{'loss': 0.3374, 'learning_rate': 1.6561295803470434e-06, 'epoch': 2.9}\n",
            "{'loss': 0.3588, 'learning_rate': 1.538790089037206e-06, 'epoch': 2.91}\n",
            "{'loss': 0.3315, 'learning_rate': 1.421450597727369e-06, 'epoch': 2.91}\n",
            "{'loss': 0.3388, 'learning_rate': 1.3041111064175315e-06, 'epoch': 2.92}\n",
            "{'loss': 0.3306, 'learning_rate': 1.1867716151076942e-06, 'epoch': 2.93}\n",
            "{'loss': 0.3467, 'learning_rate': 1.069432123797857e-06, 'epoch': 2.94}\n",
            "{'loss': 0.3646, 'learning_rate': 9.520926324880196e-07, 'epoch': 2.94}\n",
            "{'loss': 0.3116, 'learning_rate': 8.347531411781825e-07, 'epoch': 2.95}\n",
            "{'loss': 0.3069, 'learning_rate': 7.174136498683451e-07, 'epoch': 2.96}\n",
            "{'loss': 0.3472, 'learning_rate': 6.000741585585078e-07, 'epoch': 2.96}\n",
            "{'loss': 0.352, 'learning_rate': 4.827346672486706e-07, 'epoch': 2.97}\n",
            "{'loss': 0.3637, 'learning_rate': 3.6539517593883326e-07, 'epoch': 2.98}\n",
            "{'loss': 0.3333, 'learning_rate': 2.48055684628996e-07, 'epoch': 2.99}\n",
            "{'loss': 0.332, 'learning_rate': 1.3071619331915873e-07, 'epoch': 2.99}\n",
            "{'loss': 0.364, 'learning_rate': 1.3376702009321451e-08, 'epoch': 3.0}\n",
            "{'train_runtime': 10454.0942, 'train_samples_per_second': 163.042, 'train_steps_per_second': 20.38, 'train_loss': 0.4069140430814028, 'epoch': 3.0}\n",
            "100% 213057/213057 [2:54:14<00:00, 20.38it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r ../trained_model_combined.zip ../trained_model_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXMHneJ6wYkC",
        "outputId": "ac88d098-9396-45b7-e2e3-b88bc9229a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: ../trained_model_combined/ (stored 0%)\n",
            "  adding: ../trained_model_combined/vocab.txt (deflated 53%)\n",
            "  adding: ../trained_model_combined/model.safetensors (deflated 7%)\n",
            "  adding: ../trained_model_combined/config.json (deflated 54%)\n",
            "  adding: ../trained_model_combined/special_tokens_map.json (deflated 42%)\n",
            "  adding: ../trained_model_combined/training_args.bin (deflated 51%)\n",
            "  adding: ../trained_model_combined/tokenizer.json (deflated 71%)\n",
            "  adding: ../trained_model_combined/tokenizer_config.json (deflated 76%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eval"
      ],
      "metadata": {
        "id": "V66bf1hEwjN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run.py --do_eval --task nli --dataset snli --model ./trained_model_combined/ --output_dir ./eval_output_snli_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEmh91z64r_t",
        "outputId": "baaa39e0-7c20-4d8d-b1e5-2ee9bec79b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 19:40:23.732157: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-11 19:40:23.732222: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-11 19:40:23.732256: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-11 19:40:25.292237: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Preprocessing data... (this takes a little bit, should only happen once per dataset)\n",
            "Filter: 100% 10000/10000 [00:00<00:00, 72702.92 examples/s]\n",
            "Filter: 100% 550152/550152 [00:02<00:00, 214303.53 examples/s]\n",
            "Filter: 100% 10000/10000 [00:00<00:00, 240970.25 examples/s]\n",
            "Map (num_proc=2): 100% 9842/9842 [00:01<00:00, 6175.22 examples/s]\n",
            "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100% 1231/1231 [00:22<00:00, 54.82it/s]\n",
            "Evaluation results:\n",
            "{'eval_loss': 0.3825570344924927, 'eval_accuracy': 0.8922983407974243, 'eval_runtime': 22.9443, 'eval_samples_per_second': 428.953, 'eval_steps_per_second': 53.652}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run.py --do_eval --task nli --dataset breakNLIdata.jsonl --model ./trained_model_combined/ --output_dir ./eval_output_break_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6uiSZH4xp0Q",
        "outputId": "b4d7c111-d045-40b7-ed4d-26c4502e3ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 19:43:07.290971: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-11 19:43:07.291054: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-11 19:43:07.291095: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-11 19:43:09.272099: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 8507.72it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1014.10it/s]\n",
            "Generating train split: 8193 examples [00:00, 409655.27 examples/s]\n",
            "Preprocessing data... (this takes a little bit, should only happen once per dataset)\n",
            "Map (num_proc=2): 100% 8193/8193 [00:01<00:00, 5033.55 examples/s]\n",
            "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100% 1025/1025 [00:18<00:00, 56.55it/s]\n",
            "Evaluation results:\n",
            "{'eval_loss': 0.3841433525085449, 'eval_accuracy': 0.9038203358650208, 'eval_runtime': 18.5631, 'eval_samples_per_second': 441.358, 'eval_steps_per_second': 55.217}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run.py --do_eval --task nli --dataset mccoy_parsed_only_dev.jsonl --model ./trained_model_combined/ --output_dir ./eval_output_mccoylimited_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--PpAl_rx8dg",
        "outputId": "f4dd256b-c8df-4057-ccb6-d1c97f5b4771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 19:44:37.581682: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-11 19:44:37.581741: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-11 19:44:37.581777: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-11 19:44:39.357901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 8004.40it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1007.28it/s]\n",
            "Generating train split: 12000 examples [00:00, 492737.41 examples/s]\n",
            "Preprocessing data... (this takes a little bit, should only happen once per dataset)\n",
            "Map (num_proc=2): 100% 12000/12000 [00:01<00:00, 7703.16 examples/s]\n",
            "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100% 1500/1500 [00:27<00:00, 54.95it/s]\n",
            "Evaluation results:\n",
            "{'eval_loss': 0.0006270951707847416, 'eval_accuracy': 1.0, 'eval_runtime': 27.733, 'eval_samples_per_second': 432.697, 'eval_steps_per_second': 54.087}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run.py --do_eval --task nli --dataset mccoy_parsed_only_train.jsonl --model ./trained_model_combined/ --output_dir ./eval_output_mccoytrain_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yApd6NnW606f",
        "outputId": "e3b96898-0cb0-451a-c54e-45cd5bf50051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 19:46:18.797439: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-11 19:46:18.797509: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-11 19:46:18.797541: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-11 19:46:19.995776: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 10106.76it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1416.52it/s]\n",
            "Generating train split: 18000 examples [00:00, 722125.24 examples/s]\n",
            "Preprocessing data... (this takes a little bit, should only happen once per dataset)\n",
            "Map (num_proc=2): 100% 18000/18000 [00:03<00:00, 4846.91 examples/s]\n",
            "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100% 2250/2250 [00:40<00:00, 56.18it/s]\n",
            "Evaluation results:\n",
            "{'eval_loss': 0.0006274619372561574, 'eval_accuracy': 1.0, 'eval_runtime': 40.6903, 'eval_samples_per_second': 442.365, 'eval_steps_per_second': 55.296}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r eval_output_snli_combined.zip eval_output_snli_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edUP-p4tyG3Y",
        "outputId": "589e5c6a-ab90-4b30-de9b-a58ce7a2384e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: eval_output_snli_combined/ (stored 0%)\n",
            "  adding: eval_output_snli_combined/runs/ (stored 0%)\n",
            "  adding: eval_output_snli_combined/runs/Nov11_19-40-26_fbcaa77cda87/ (stored 0%)\n",
            "  adding: eval_output_snli_combined/runs/Nov11_19-40-26_fbcaa77cda87/events.out.tfevents.1699731661.fbcaa77cda87.47330.0 (deflated 23%)\n",
            "  adding: eval_output_snli_combined/eval_predictions.jsonl (deflated 77%)\n",
            "  adding: eval_output_snli_combined/eval_metrics.json (deflated 32%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r eval_output_break_combined.zip eval_output_break_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX2u04_YyXUD",
        "outputId": "0e1d5a52-dd31-48f8-8535-980e51a2e605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: eval_output_break_combined/ (stored 0%)\n",
            "  adding: eval_output_break_combined/runs/ (stored 0%)\n",
            "  adding: eval_output_break_combined/runs/Nov11_19-43-10_fbcaa77cda87/ (stored 0%)\n",
            "  adding: eval_output_break_combined/runs/Nov11_19-43-10_fbcaa77cda87/events.out.tfevents.1699731813.fbcaa77cda87.48055.0 (deflated 23%)\n",
            "  adding: eval_output_break_combined/eval_predictions.jsonl (deflated 82%)\n",
            "  adding: eval_output_break_combined/eval_metrics.json (deflated 30%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r eval_output_mccoylimited_combined.zip eval_output_mccoylimited_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz2vt3HeybLx",
        "outputId": "c9e25206-5cf2-4d6e-859e-b3ef9417179b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: eval_output_mccoylimited_combined/ (stored 0%)\n",
            "  adding: eval_output_mccoylimited_combined/runs/ (stored 0%)\n",
            "  adding: eval_output_mccoylimited_combined/runs/Nov11_19-44-40_fbcaa77cda87/ (stored 0%)\n",
            "  adding: eval_output_mccoylimited_combined/runs/Nov11_19-44-40_fbcaa77cda87/events.out.tfevents.1699731912.fbcaa77cda87.48474.0 (deflated 23%)\n",
            "  adding: eval_output_mccoylimited_combined/eval_predictions.jsonl (deflated 81%)\n",
            "  adding: eval_output_mccoylimited_combined/eval_metrics.json (deflated 29%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r eval_output_mccoytrain.zip eval_output_mccoytrain_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb6EcqcE7MjN",
        "outputId": "00034cdf-05e4-4bd5-e166-2065c36eae94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: eval_output_mccoytrain_combined/ (stored 0%)\n",
            "  adding: eval_output_mccoytrain_combined/runs/ (stored 0%)\n",
            "  adding: eval_output_mccoytrain_combined/runs/Nov11_19-46-20_fbcaa77cda87/ (stored 0%)\n",
            "  adding: eval_output_mccoytrain_combined/runs/Nov11_19-46-20_fbcaa77cda87/events.out.tfevents.1699732028.fbcaa77cda87.48941.0 (deflated 23%)\n",
            "  adding: eval_output_mccoytrain_combined/eval_predictions.jsonl (deflated 82%)\n",
            "  adding: eval_output_mccoytrain_combined/eval_metrics.json (deflated 28%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run.py --do_eval --task nli --dataset mccoy_parsed_only_train.jsonl --model ./trained_model_combined/ --output_dir ./eval_output_mccoytrain_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NpB-67RzG3L",
        "outputId": "28855987-03d0-45c0-e171-23d1b2a9b2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-10 19:54:47.623502: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-10 19:54:47.623565: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-10 19:54:47.623620: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-10 19:54:49.040955: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 7884.03it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1194.62it/s]\n",
            "Generating train split: 18000 examples [00:00, 675767.96 examples/s]\n",
            "Preprocessing data... (this takes a little bit, should only happen once per dataset)\n",
            "Map (num_proc=2): 100% 18000/18000 [00:02<00:00, 6124.12 examples/s]\n",
            "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100% 2250/2250 [00:45<00:00, 49.91it/s]\n",
            "Evaluation results:\n",
            "{'eval_loss': 0.0007742965244688094, 'eval_accuracy': 0.9999444484710693, 'eval_runtime': 45.559, 'eval_samples_per_second': 395.092, 'eval_steps_per_second': 49.387}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r eval_output_mccoytrain_combined.zip eval_output_mccoytrain_combined"
      ],
      "metadata": {
        "id": "DzEwm3q60FTk",
        "outputId": "94b249cc-e4a0-4256-d045-da011aced559",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: eval_output_mccoytrain_combined/ (stored 0%)\n",
            "  adding: eval_output_mccoytrain_combined/runs/ (stored 0%)\n",
            "  adding: eval_output_mccoytrain_combined/runs/Nov10_19-54-49_769b8db75708/ (stored 0%)\n",
            "  adding: eval_output_mccoytrain_combined/runs/Nov10_19-54-49_769b8db75708/events.out.tfevents.1699646140.769b8db75708.58251.0 (deflated 23%)\n",
            "  adding: eval_output_mccoytrain_combined/eval_metrics.json (deflated 31%)\n",
            "  adding: eval_output_mccoytrain_combined/eval_predictions.jsonl (deflated 81%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eval baseline on 40% mccoy"
      ],
      "metadata": {
        "id": "-A_Ln7C2B6Rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run.py --do_eval --task nli --dataset mccoy_parsed_only_dev.jsonl --model ./trained_model/ --output_dir ./eval_output_baseline_on_40mccoy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIo1SBIWB69J",
        "outputId": "fbabbfbf-76be-4281-beff-5eda684401f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-16 12:27:27.301579: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-16 12:27:27.301636: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-16 12:27:27.301685: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-16 12:27:29.138544: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 8594.89it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1246.08it/s]\n",
            "Generating train split: 12000 examples [00:00, 375502.83 examples/s]\n",
            "Preprocessing data... (this takes a little bit, should only happen once per dataset)\n",
            "Map (num_proc=2): 100% 12000/12000 [00:01<00:00, 7252.80 examples/s]\n",
            "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100% 1500/1500 [00:28<00:00, 52.96it/s]\n",
            "Evaluation results:\n",
            "{'eval_loss': 2.4383528232574463, 'eval_accuracy': 0.51583331823349, 'eval_runtime': 31.1721, 'eval_samples_per_second': 384.959, 'eval_steps_per_second': 48.12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r eval_output_baseline_on_40mccoy.zip eval_output_baseline_on_40mccoy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrV0-0IcGdlQ",
        "outputId": "1528e48b-e510-476e-d883-b92101fe7a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: eval_output_baseline_on_40mccoy/ (stored 0%)\n",
            "  adding: eval_output_baseline_on_40mccoy/eval_metrics.json (deflated 30%)\n",
            "  adding: eval_output_baseline_on_40mccoy/runs/ (stored 0%)\n",
            "  adding: eval_output_baseline_on_40mccoy/runs/Nov16_12-27-29_939eb5b3251f/ (stored 0%)\n",
            "  adding: eval_output_baseline_on_40mccoy/runs/Nov16_12-27-29_939eb5b3251f/events.out.tfevents.1700137688.939eb5b3251f.8706.0 (deflated 23%)\n",
            "  adding: eval_output_baseline_on_40mccoy/eval_predictions.jsonl (deflated 81%)\n"
          ]
        }
      ]
    }
  ]
}